{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning approach to Detect Anomalies in Blockchain using Federated Learning\n",
    "## Libraries I have used for implementing\n",
    "#### 1. PyTorch (https://pytorch.org/)\n",
    "#### 2. PySyft ( https://github.com/OpenMined/PySyft )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import namegenerator\n",
    "import hashlib as hasher ## For using hash functions\n",
    "import datetime as date \n",
    "import torch\n",
    "import syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hook creates virtual addresses to each data item\n",
    "hook = syft.TorchHook(torch)\n",
    "\n",
    "## Creating list for names of a transactions\n",
    "names = list()\n",
    "\n",
    "## Creating list for tranasaction_id\n",
    "transaction = list()\n",
    "\n",
    "## Labels for each each transaction either it was anamoly or correct\n",
    "labels = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Generating 50 transaction names and their id's\n",
    "\n",
    "i = 0\n",
    "while i < 50:\n",
    "    name = namegenerator.gen()\n",
    "    names.append(name)\n",
    "    transaction_id = random.randint(100000000000000,999999999999999)\n",
    "    transaction.append(transaction_id)\n",
    "    label = random.randint(0,1)\n",
    "    labels.append(label)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Now let's see the fifty transaction id's and their labels\n",
    "\n",
    "for i in range(20):\n",
    "    print( \"Name -->\",names[i] , \"Transaction id -->:\",transaction[i], \"Label -->\",labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Now I'm going to create a Blockchain for 50 transactions\n",
    "\n",
    "class Block:    \n",
    "    def __init__(self, name, transaction_id,label):\n",
    "        self.name = name\n",
    "        self.transaction_id = transaction_id\n",
    "        self.label = label\n",
    "        self.hash = self.hash_block()\n",
    "\n",
    "    def hash_block(self):\n",
    "        sha = hasher.sha256()\n",
    "        sha.update(str(self.name).encode('utf-8') + \n",
    "                   str(self.transaction_id).encode('utf-8') + \n",
    "                   str(self.label).encode('utf-8'))\n",
    "        return sha.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_0 = names[0]\n",
    "transaction_0 = transaction[0]\n",
    "labels_0 = labels[0]\n",
    "name_0,transaction_0,labels_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## create_genesis_block() which creates initial block of the chain\n",
    "\n",
    "def create_genesis_block():\n",
    "    \n",
    "    return Block(name_0, transaction_0,labels_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## After create_genesis_block() has been called this next_block() will create attach each transaction and their label id's to \n",
    "## blockchain\n",
    "\n",
    "def next_block(last_block,j):\n",
    "    this_name = names[j]\n",
    "    this_transaction_id = transaction[j]\n",
    "    this_label = labels[j]\n",
    "    this_hash = last_block.hash\n",
    "    return Block(this_name, this_transaction_id,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockchain = [create_genesis_block()]\n",
    "previous_block = blockchain[0]\n",
    "num_of_blocks_to_add = len(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## Now, Let's see the each transaction name,id,label and Hash Function\n",
    "\n",
    "for i in range(0, num_of_blocks_to_add):\n",
    "    block_to_add = next_block(previous_block,i)\n",
    "    blockchain.append(block_to_add)\n",
    "    previous_block = block_to_add\n",
    "    print(\"Name: {}\\n\".format(block_to_add.name))\n",
    "    print(\"transaction_id: {}\\n\".format(block_to_add.transaction_id))\n",
    "    print(\"Label: {}\\n\".format(block_to_add.label))    \n",
    "    print(\"Hash: {}\\n\".format(block_to_add.hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Creating 50 new names for VirtualWorker creation\n",
    "\n",
    "a = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\"aa\",\"bb\",\"cc\",\n",
    "     \"dd\",\"ee\",\"ff\",\"gg\",\"hh\",\"ii\",\"jj\",\"kk\",\"ll\",\"mm\",\"nn\",\"oo\",\"pp\",\"qq\",\"rr\",\"ss\",\"tt\",\"uu\",\"vv\",\"ww\",\"xx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## So, Inorder to set each transaction to remote we've to use VirtualWorker method in PySyft package. It will creates addresses\n",
    "## for each transaction.\n",
    "\n",
    "\n",
    "for i in range(len(names)):\n",
    "    names[i] = syft.VirtualWorker(hook, id = names[i])\n",
    "    a[i] = torch.tensor([transaction[i]]).send(names[i])\n",
    "    b[i] = torch.tensor([labels[i]]).send(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Let's see the each transaction_id and their label address\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(\"Transaction_id address -->\", a[i],\"\\n Label address -->\",b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(names)):\n",
    "    datasets.append((a[i],b[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(datasets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Importing nn,optim classes from PyTorch to train my model\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Creating model\n",
    "\n",
    "\n",
    "def train(iterations = 20):\n",
    "    model = nn.Linear(50,2)\n",
    "    optimizer_fed = optim.SGD(params = model.parameters(), lr = 0.1)\n",
    "    for iter in range(iterations):\n",
    "        for data, target  in datasets:\n",
    "            \n",
    "            ## Here model.send() will goes each transaction present in remotely and trained their and move to the next \n",
    "            ## trasaction\n",
    "            \n",
    "            model = model.send(data.location)\n",
    "            optimizer_fed.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = (( pred - target) ** 2).sum()\n",
    "            loss.backward()\n",
    "            optimizer_fed.step()\n",
    "            model = model.get()\n",
    "            print(loss.get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## Finally training\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
